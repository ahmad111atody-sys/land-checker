import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def check_land_project(url):
    headers = {
        "User-Agent": "Mozilla/5.0"
    }
    response = requests.get(url, headers=headers)
    response.encoding = "utf-8"
    
    soup = BeautifulSoup(response.text, "html.parser")
    links = []

    # Ù†Ø¨Ø­Ø« Ø¹Ù† Ø£ÙŠ Ø¹Ù†ØµØ± ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© "Ù…Ù„ØºØ§Ø©" Ø£Ùˆ "Canceled"
    for a in soup.find_all("a", href=True):
        if "Ù…Ù„ØºØ§Ø©" in a.text or "Canceled" in a.text:
            full_link = "https://sakani.sa" + a["href"] if a["href"].startswith("/") else a["href"]
            links.append(full_link)

    status = "ğŸ”´ ÙŠÙˆØ¬Ø¯ Ù‚Ø·Ø¹ Ù…Ù„ØºØ§Ø©" if links else "ğŸŸ¢ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù‚Ø·Ø¹ Ù…Ù„ØºØ§Ø©"
    
    result = {
        "checked_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "project_url": url,
        "status": status,
        "links": links
    }
    
    return result


# ========== ØªÙ†ÙÙŠØ° Ù…Ø¨Ø§Ø´Ø± ==========
if __name__ == "__main__":
    url = input("Ø¶Ø¹ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø®Ø·Ø· Ù…Ù† Ø³ÙƒÙ†ÙŠ Ù‡Ù†Ø§: ").strip()
    data = check_land_project(url)
    print(json.dumps(data, ensure_ascii=False, indent=2))
