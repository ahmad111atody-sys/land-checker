#!/usr/bin/env python3
# combined_sakani_checker.py
# ğŸ”¹ ÙØ­Øµ Ù…Ø®Ø·Ø·Ø§Øª Ø³ÙƒÙ†ÙŠ (Ø§Ù„Ø¨Ø³ØªØ§Ù† + Ø§Ù„Ù†Ø®Ù„Ø§Ù† + Ø§Ù„Ù†Ø´Ø·Ø©)

from flask import Flask, jsonify, request
import requests
from bs4 import BeautifulSoup
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Flask
app = Flask(__name__)
app.config['JSON_AS_ASCII'] = False  # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø¯ÙˆÙ† ØªØ±Ù…ÙŠØ²

# Ù…ÙØªØ§Ø­ ScraperAPI (Ø¥Ø°Ø§ Ø¹Ù†Ø¯Ùƒ)
SCRAPER_API_KEY = os.getenv("SCRAPER_API_KEY", "YOUR_SCRAPER_API_KEY")

# Ø±ÙˆØ§Ø¨Ø· Ù…Ø®Ø·Ø· Ø§Ù„Ø¨Ø³ØªØ§Ù†
alobstan_links = [
    "https://sakani.sa/app/units/765316",
    "https://sakani.sa/app/units/765453",
    "https://sakani.sa/app/units/765499",
    "https://sakani.sa/app/units/765587",
    "https://sakani.sa/app/units/765778",
    "https://sakani.sa/app/units/765515",
    "https://sakani.sa/app/units/765448",
    "https://sakani.sa/app/units/765595",
    "https://sakani.sa/app/units/765577",
    "https://sakani.sa/app/units/765205"
]

# Ø±ÙˆØ§Ø¨Ø· Ù…Ø®Ø·Ø· Ù†Ø®Ù„Ø§Ù†
nakhlan_links = [
    "https://sakani.sa/app/units/797389",
    "https://sakani.sa/app/units/797400",
    "https://sakani.sa/app/units/797412",
    "https://sakani.sa/app/units/797420",
    "https://sakani.sa/app/units/797431",
    "https://sakani.sa/app/units/797440",
    "https://sakani.sa/app/units/797456",
    "https://sakani.sa/app/units/797468"
]

# Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ø·Ø¹ Ø§Ù„Ù†Ø´Ø·Ø© Ù…Ù† active_units.txt
active_units_links = [
    # Ø£Ø¶Ù Ø±ÙˆØ§Ø¨Ø·Ùƒ Ù‡Ù†Ø§ Ù„Ø§Ø­Ù‚Ø§Ù‹ Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ Ù…Ù„Ù active_units
]


# Ø¯Ø§Ù„Ø© Ø§Ù„ÙØ­Øµ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
def fetch_land(url, timeout=30):
    try:
        api_key = SCRAPER_API_KEY
        if api_key and api_key != "YOUR_SCRAPER_API_KEY":
            api_url = f"http://api.scraperapi.com/?api_key={api_key}&url={url}"
            resp = requests.get(api_url, timeout=timeout)
        else:
            resp = requests.get(url, timeout=timeout)

        if resp.status_code != 200:
            return {"error": "fetch_failed", "status_code": resp.status_code, "url": url}

        soup = BeautifulSoup(resp.text, "html.parser")
        title_tag = soup.find("title")
        title = title_tag.text.strip() if title_tag else "ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ"

        project_id = url.split("/")[-1]
        return {"project": project_id, "status": "success", "title": title, "url": url}

    except requests.Timeout:
        return {"error": "timeout", "url": url}
    except Exception as e:
        return {"error": str(e), "url": url}


@app.route("/")
def home():
    return jsonify({"status": "running", "message": "Land checker is online âœ…"})


# âœ… ÙØ­Øµ Ø§Ù„Ø¨Ø³ØªØ§Ù† ÙÙ‚Ø·
@app.route("/check_alobstan", methods=["GET"])
def check_alobstan():
    results = []
    for u in alobstan_links:
        results.append(fetch_land(u))
    return jsonify(results)


# âœ… ÙØ­Øµ Ù†Ø®Ù„Ø§Ù† ÙÙ‚Ø·
@app.route("/check_nakhlan", methods=["GET"])
def check_nakhlan():
    results = []
    for u in nakhlan_links:
        results.append(fetch_land(u))
    return jsonify(results)


# âœ… ÙØ­Øµ Ø§Ù„Ù‚Ø·Ø¹ Ø§Ù„Ù†Ø´Ø·Ø© ÙÙ‚Ø·
@app.route("/check_active", methods=["GET"])
def check_active():
    results = []
    for u in active_units_links:
        results.append(fetch_land(u))
    return jsonify(results)


# âœ… ÙØ­Øµ Ø´Ø§Ù…Ù„ (Ø§Ù„Ø¨Ø³ØªØ§Ù† + Ù†Ø®Ù„Ø§Ù† + Ø§Ù„Ù†Ø´Ø·Ø©)
@app.route("/check_all", methods=["GET"])
def check_all():
    results = {"alobstan": [], "nakhlan": [], "active_units": []}
    for u in alobstan_links:
        results["alobstan"].append(fetch_land(u))
    for u in nakhlan_links:
        results["nakhlan"].append(fetch_land(u))
    for u in active_units_links:
        results["active_units"].append(fetch_land(u))
    return jsonify(results)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=False)
